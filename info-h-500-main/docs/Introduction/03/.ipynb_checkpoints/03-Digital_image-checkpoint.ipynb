{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import HTML,Image,SVG,YouTubeVideo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A digital image is discrete. It means that there is somewhere in the acquisition process, most of the time, sampling that occurs.\n",
    "\n",
    "A digital image is basically a multidimentionnal array of numbers. Each picture element store a numerical value, with 2D images we speak about **pixels** (from PIcture ELements) and for 3D images we use **voxels** (from VOlume ELements).\n",
    "\n",
    "The latice of pixels are usually rectangular (or square if pixels are squares) or hexagonal, hexagonal latice has a unique distance between a pixel and its neghboors.\n",
    "\n",
    "The image dimentionnality will depend on:\n",
    "\n",
    "* the spatial dimentionnality: 1D or profile, 2D image, 3D volume\n",
    "\n",
    "* the temporal dimension: add one dimension for the time when dealing with **sequences**\n",
    "\n",
    "* the spectral dimension: the number of spectral values associated with on image element\n",
    "\n",
    "\n",
    "The spatial dimension is given, typically, by the grid step of the sensor. A 640x480 CMOS sensor will produce a 640x480 pixels grid.\n",
    "\n",
    "For a flatbed scanner, one dimension will be given by the number of sensor along the acquisition line, while the second dimension will be given by the spacial repetition of a line acquisition.\n",
    "\n",
    "One remark concerning these images: the shape of the pixels is not always a square, depending on the sensor geometry and/or the sampling speed (i.e.for the scanners).\n",
    "One have to pay attention to that, in particular when we will extract measures from images (e.g. distance or surface).\n",
    "\n",
    "When acquisition is a sequence one add one dimension for the time. \n",
    "\n",
    "Similarily, image can be composed of different spectral band.\n",
    "\n",
    "For example, a time-lapse acquisition of fluorescent confocal microscopy can have 5-D:\n",
    "* three X,Y and Z spatial dimensions (voxels)\n",
    "* one spectral dimension , i.e. several fluorophore channels (e.g. dapi, alexa, GFP)\n",
    "* one time dimension (time-lapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add example of embryo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image sampling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from skimage.data import camera\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def build_gaussian_pyramid(ima,levelmax):\n",
    "    \"\"\"return a list of subsampled images (using gaussion pre-filter\n",
    "    \"\"\"\n",
    "    r = [ima]\n",
    "    current = ima\n",
    "    for level in range(levelmax):\n",
    "        lp = gaussian_filter(current,1.0)\n",
    "        sub = lp[::2,::2]\n",
    "        current = sub\n",
    "        r.append(current)\n",
    "    return r\n",
    "\n",
    "def build_pyramid(ima,levelmax):\n",
    "    \"\"\"return a list of subsampled images (using gaussion pre-filter\n",
    "    \"\"\"\n",
    "    r = [ima]\n",
    "    current = ima\n",
    "    for level in range(levelmax):\n",
    "        sub = current[::2,::2]\n",
    "        current = sub\n",
    "        r.append(current)\n",
    "    return r\n",
    "\n",
    "im = camera()[::2,::2]\n",
    "\n",
    "#build filtered and non-filtered pyramids\n",
    "N = 4\n",
    "fpyramid = build_gaussian_pyramid(im,N)\n",
    "nfpyramid = build_pyramid(im,N)\n",
    "\n",
    "for f,nf in zip(fpyramid,nfpyramid):\n",
    "\n",
    "    plt.figure(figsize=[7,7])\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(f,cmap=plt.cm.gray,interpolation='nearest')\n",
    "    plt.title('guaussian pyramid')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(nf,cmap=plt.cm.gray,interpolation='nearest')\n",
    "    plt.title('subsampling pyramid');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = camera()\n",
    "plt.figure(figsize=[12,12])\n",
    "    \n",
    "for s in range(0,8):\n",
    "    g_poster = (g>>s)\n",
    "\n",
    "    plt.subplot(3,3,s+1)\n",
    "    plt.imshow(g_poster,cmap=cm.gray)\n",
    "    plt.colorbar()\n",
    "    plt.gca().set_xticklabels([])\n",
    "    plt.gca().set_yticklabels([])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entropy of a signal is given by:\n",
    "\n",
    "$$h = -\\sum_i {p_i \\log {p_i}}$$\n",
    "\n",
    "where $p_i$ is the probability of occurence of a symbol $i$.\n",
    "\n",
    "For a gray scale image, one can consider the gray level distribution as the 'probablility' of occurence of a gray level. The following example illustrate how image entropy vary with respect to the graylevel distribution.\n",
    "\n",
    "If the logarithm base used is 2, the entropy corresponds to the number of bits required to encode the signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> see also:\n",
    "* image entropy **[IPAMV]** p19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from skimage.data import camera\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def display_hist(ima,nbin):\n",
    "    hist,bins = np.histogram(ima.flatten(),bins=range(0,nbin+1))\n",
    "    norm_hist = 1.*hist/np.sum(hist) # normalized histogram\n",
    "    # entropy\n",
    "    idx = norm_hist>0\n",
    "    h = -np.sum(norm_hist[idx]*np.log2(norm_hist[idx]))\n",
    "    \n",
    "    # display the results\n",
    "    plt.figure(figsize=[10,3])\n",
    "    ax = plt.subplot(1,2,1)\n",
    "    plt.imshow(ima,cmap=cm.gray,interpolation='nearest')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax = plt.subplot(1,2,2)\n",
    "    plt.bar(bins[:-1],hist,.8)\n",
    "    if len(bins)<10:\n",
    "        ax.set_xticks(bins[:-1])\n",
    "        ax.set_xticklabels( bins[:-1] )\n",
    "    plt.xlabel('gray level')\n",
    "    plt.ylabel('occurence');\n",
    "    plt.title('entropy = %.2f'%h)\n",
    "    \n",
    "    \n",
    "i1 = np.array([[1,2,3,0],[1,2,3,0],[1,2,3,0]])\n",
    "i2 = np.array([[1,3,1,3],[3,1,3,1],[1,3,1,3]])\n",
    "i3 = np.array([[3,3,3,3],[3,3,3,3],[3,3,3,3]])\n",
    "\n",
    "display_hist(i1,4)\n",
    "display_hist(i2,4)\n",
    "display_hist(i3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.data import camera\n",
    "ima = camera()[::2,::2]\n",
    "display_hist(ima,255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entropy of the above image is 7.05, it means that we need a bit more than 7 bits to encode graylevel for this image. Which is consistent with the choosen data storage (8 bit per pixel). \n",
    "\n",
    "Entropy is often known as an information measure.\n",
    "\n",
    "But what would be the entropy of an image where all the pixels are randomly permuted ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly permutes all the image pixels\n",
    "d = ima.flatten()\n",
    "shuffled_ima = np.random.permutation(d.flatten())\n",
    "shuffled_ima = shuffled_ima.reshape(ima.shape)\n",
    "\n",
    "display_hist(shuffled_ima,255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the entropy is computed on the graylevel **distribution**, nothing changes. So, from the entropy point of view, information carried by the above image is the same as the one of the cameraman, something about the way we define the information is wrong here...\n",
    "\n",
    "In fact, when we shuffle the pixels of the image, we lose the localisation information, pixels that where located close to each other are splitted.\n",
    "\n",
    "In order to take this colocality between pixels, one can use the coocurence matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coocurence matrix\n",
    "\n",
    "def cooc(im,dx,dy):\n",
    "    rim = np.roll(im,dy,axis=0)\n",
    "    rim = np.roll(rim,dx,axis=1)\n",
    "    G1 = im.flatten()\n",
    "    G2 = rim.flatten()\n",
    "    \n",
    "    histo2D = np.zeros((256,256))\n",
    "\n",
    "    for g1,g2 in zip(G1,G2):\n",
    "        histo2D[g1,g2] = histo2D[g1,g2]+1\n",
    "        \n",
    "    return histo2D, rim\n",
    "\n",
    "dx = -10\n",
    "dy = -5\n",
    "histo2D,rim = cooc(ima,dx=dx,dy=dy)\n",
    "plt.figure(figsize=[7,7])\n",
    "plt.imshow(rim,cmap=cm.gray,interpolation='nearest');\n",
    "plt.arrow(200,50,-dx,-dy,color='b',head_width=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an image $I$ one define a coocurance matrix by:\n",
    "$$\n",
    "C^{\\Delta x, \\Delta y}_{i,j}=\\sum_{p=1}^n\\sum_{q=1}^m\\begin{cases} 1, & \\mbox{if }I(p,q)=i\\mbox{ and }I(p+\\Delta x,q+\\Delta y)=j \\\\ 0, &\\mbox{otherwise}\\end{cases}\n",
    "$$\n",
    "\n",
    "in other words, this matrix count the number of pixels having a gray level $i$ and its neighboor, defined by the $(\\Delta x, \\Delta y)$ translation, has a gray level $j$.\n",
    "\n",
    "Usually close pixels share a similar gray level, for small $(\\Delta x, \\Delta y)$ the matrix is close to the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(histo2D)\n",
    "plt.ylim([0,255])\n",
    "plt.title('Coocurence matrix $\\Delta = (%d,%d)$'%(dx,dy));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice: \n",
    "1. what contains the diagonal of a coocurence matrix with $(\\Delta x, \\Delta y) = (0,0)$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the impact of our previous shuffling on the coocurence matrix ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histo2D,_ = cooc(shuffled_ima,dx=dx,dy=dy)\n",
    "plt.imshow(histo2D)\n",
    "plt.ylim([0,255])\n",
    "plt.title('Coocurence matrix $\\Delta = (%d,%d)$'%(dx,dy));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice:\n",
    "1. evaluate the entropy of the coocurence matrices of the cameraman image \n",
    "2. do the same with its shuffled version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> see also:\n",
    "* cooccurence matrix **[IPAMV]** p45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compression\n",
    "\n",
    "The aim of the compression can be to limit the size of the image in memory, for the storage, for the transmission. Depending n its use, compression can be lossless, i.e. the data remains untouched after decompression, or, the compression can be lossy if one tolerate some data degradation to have better compression. Image compression used redundancy present in the image to limit the actual number of bits to be used, for example continuity in an image, or in a sequence (video compression).\n",
    "\n",
    "## Lossless compression\n",
    "We give here two examples of compression that can be used to diminish the amount of bits to be used to store/transmit a data without changing its content.\n",
    "\n",
    "### Huffman encoding\n",
    "This method compress sequence of symbols (i.e. one can think of pixel graylevels) such that one take advantages of the unequal distribution if the occurence of symbols. Indeed if a symbol is very common, let's a gray level often used, it could be interesting to stor its value with a very short (in terms of bits) symbol. On a contrary, a very rare symbol could use more bits without penalizing the average total message length.\n",
    "\n",
    "In the given example hereunder, four symbols have a variable frequency of occurence, from a1 the most frequent to a4 the less one.\n",
    "\n",
    "With the Huffman method we first associate the shortest code '0' to the most frequent symbol 'a1', all the other symbols will be coded by a word begining by '1'.\n",
    "\n",
    "The same process is done recursively for the remaining symbols. Finally the rarest symbol will be coded by 3 bits, whereas normaly only 2 bits are sufficient for coding 1 symbol out of 4. But statistically, because a very short word is used for the most frequent symbol, the length of the total message will be shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('https://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Huffman_coding_example.svg/320px-Huffman_coding_example.svg.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<sup>[wikimedia commons](https://commons.wikimedia.org/wiki/File:Huffman_coding_example.svg)<sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice:\n",
    "1. apply the Huffman comression to a grayscale 8-bits image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> see also:\n",
    "* Huffman encoding **[DIPM]** pp261-269"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run length encoding\n",
    "\n",
    "When image is binary, one can group consecutive similar pixels (0 or 1) and encode them by saving the length of the sequence only. Of course the encoded image is stored in integer, big enough to store the longuest segment (35 in the given example).\n",
    "If the image has a lot of continuous parts, this compression can be very efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('http://pippin.gimp.org/image_processing/images/rle.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<sup>[image source](http://pippin.gimp.org/image_processing/images/rle.png)<sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice:\n",
    "1. propose a method for labelled image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> see also:\n",
    "* Run-legth encoding **[IPH]** p396"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image pyramid\n",
    "\n",
    "How to better use the intrinsic image properties such as the continuity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('PyramidCompression.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split(im):\n",
    "    if im.shape[0] > 1:\n",
    "        a = im[0:-1:2,0:-1:2]\n",
    "        b = im[0:-1:2,1::2]-a\n",
    "        c = im[1::2,0:-1:2]-a\n",
    "        d = im[1::2,1::2]-a\n",
    "        R = np.vstack((np.hstack((split(a),b)),np.hstack((c,d))))\n",
    "    else:\n",
    "        R = im\n",
    "    return R\n",
    "\n",
    "im = camera()[::2,::2].astype(np.int)\n",
    "s = split(im)\n",
    "\n",
    "fig = plt.figure(figsize=[10,10])\n",
    "plt.imshow(s,interpolation='nearest',cmap=cm.gray,vmin=-255, vmax=255)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercices : \n",
    "\n",
    "1. rebuild the original image from its compressed pyramid.\n",
    "2. compute image entropy of the compressed pyramid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lossy image compression \n",
    "jpeg/dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> see also:\n",
    "* image pyramid (compression) **[DIPM]** p304\n",
    "* lossy image compression (jpeg/dct) **[IPH]** p126"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color representation\n",
    "\n",
    "Color vision is due to the ability of the eye to discriminate three part of the spectrum thanks to specialized light sensitive cells, the cones. Color image are based on the same principle, the image is composed of the contributions of the light in several spectral bands. For usual picture these bands are red, green and blue. For the human vision, every color is a combination of these (additive) colors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('https://upload.wikimedia.org/wikipedia/commons/thumb/5/5f/CIE-1931_diagram_in_LAB_space.svg/500px-CIE-1931_diagram_in_LAB_space.svg.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<sup>[wikimedia commons](https://commons.wikimedia.org/wiki/File:CIE-1931_diagram_in_LAB_space.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## color systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage import color\n",
    "from skimage.data import astronaut,immunohistochemistry\n",
    "\n",
    "rgb = astronaut()\n",
    "plt.figure(figsize=[10,10])\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(rgb[:,:,0],cmap=cm.gray)\n",
    "plt.title('red')\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(rgb[:,:,1],cmap=cm.gray)\n",
    "plt.title('green')\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(rgb[:,:,2],cmap=cm.gray)\n",
    "plt.title('blue')\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(rgb,cmap=cm.gray)\n",
    "plt.title('rgb');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = immunohistochemistry()\n",
    "\n",
    "fig = plt.figure(0)\n",
    "plt.imshow(rgb,origin='lower')\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "#subsample\n",
    "print(rgb.shape)\n",
    "rgb = rgb[::10,::10,:]\n",
    "\n",
    "r = rgb[:,:,0].flatten()\n",
    "g = rgb[:,:,1].flatten()\n",
    "b = rgb[:,:,2].flatten()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "col = np.vstack((r,g,b)).T/255.0\n",
    "ax.scatter(r,g,b,c=col)\n",
    "ax.set_xlabel('Red')\n",
    "ax.set_ylabel('Green')\n",
    "ax.set_zlabel('Blue');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('https://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/HSV_color_solid_cylinder.png/320px-HSV_color_solid_cylinder.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<sup>[wikimedia commons](https://commons.wikimedia.org/wiki/File:HSV_color_solid_cylinder_alpha_lowgamma.png)<sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = color.rgb2hsv(rgb)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "h = hsv[:,:,0].flatten()\n",
    "s = hsv[:,:,1].flatten()\n",
    "v = hsv[:,:,2].flatten()\n",
    "ax.scatter(h,s,v,c=col)\n",
    "ax.set_xlabel('Hue')\n",
    "ax.set_ylabel('Saturation')\n",
    "ax.set_zlabel('Value'),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XYZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz = color.rgb2xyz(rgb)\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "x = s*np.cos(h*2*np.pi)\n",
    "y = s*np.sin(h*2*np.pi)\n",
    "z = v\n",
    "ax.scatter(x,y,z,c=col)\n",
    "\n",
    "th = np.linspace(0,6.28,200)\n",
    "ax.scatter(np.cos(th),np.sin(th),0,c='k',s=.1);\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
