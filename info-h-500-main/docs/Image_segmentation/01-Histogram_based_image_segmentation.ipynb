{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import HTML,Image,SVG,YouTubeVideo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram based segmentation\n",
    "\n",
    "All the pixels in the image are processed the same way.\n",
    "\n",
    "* common method\n",
    "* easy and fast\n",
    "* used when pixel value has a direct interpretation \n",
    "\n",
    "e.g. Hounsfield Unit in CT scan\n",
    "$$HU = 1000\\times\\frac{\\mu - \\mu_{water}}{\\mu_{water} - \\mu_{air}}$$\n",
    "\n",
    "Imaging: Substance densities in Hounsfield Units (Radiodensity)\n",
    "\n",
    "    Air: -1000\n",
    "    Lung: -700\n",
    "    Soft Tissue: -300 to -100\n",
    "    Fat: -50\n",
    "    Water: 0\n",
    "    CSF: +15\n",
    "    Blood: +30 to +45\n",
    "    Muscle: +40\n",
    "    Calculus: +100 to +400\n",
    "    Bone: +1000 (up to +3000 for dense bone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('http://crashingpatient.com/wp-content/images/part1/tissuedensities.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a problem can arise when:\n",
    "* the illumination is uneven\n",
    "* in presence of shadows\n",
    "* when the object of interest has a variable brightness or texture, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Image threshold\n",
    "\n",
    "definition\n",
    "\n",
    "$$\\begin{align*} \n",
    "g(i,j) &= 1 \\, \\text{if} \\, f(i,j)>T \\\\\n",
    "\\,  &= 0 \\, \\text{otherwise}\n",
    "\\end{align*}$$\n",
    "\n",
    "$T$ can be:\n",
    "* fixed: $T = T0$\n",
    "* globally adaptive: $T = T(f)$\n",
    "* locally adaptive: $T = T(f,fc)$\n",
    "\n",
    "### some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def norm_hist(ima):\n",
    "    hist,bins = np.histogram(ima.flatten(),range(256))  # histogram is computed on a 1D distribution --> flatten()\n",
    "    return 1.*hist/np.sum(hist) # normalized histogram\n",
    "\n",
    "def display_hist(ima):\n",
    "    plt.figure(figsize=[10,5])\n",
    "    if ima.ndim == 2:\n",
    "        nh = norm_hist(ima)\n",
    "    else:\n",
    "        nh_r = norm_hist(ima[:,:,0])\n",
    "        nh_g = norm_hist(ima[:,:,1])\n",
    "        nh_b = norm_hist(ima[:,:,2])\n",
    "    # display the results\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(ima,cmap=plt.cm.gray)\n",
    "    plt.subplot(1,2,2)\n",
    "    if ima.ndim == 2:\n",
    "        plt.plot(nh,label='hist.')\n",
    "    else:\n",
    "        plt.plot(nh_r,color='r',label='r')\n",
    "        plt.plot(nh_g,color='g',label='g')\n",
    "        plt.plot(nh_b,color='b',label='b')\n",
    "    plt.legend()\n",
    "    plt.xlabel('gray level');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = data.horse()[:].astype(np.uint8)\n",
    "display_hist(g)\n",
    "h = np.histogram(g,range(10))\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    display_hist(data.checkerboard()>128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_hist(data.page())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = data.page()\n",
    "t = g>110\n",
    "plt.imshow(t)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import rank as skr\n",
    "from skimage.morphology import disk\n",
    "\n",
    "g = data.page()\n",
    "m = skr.median(g,disk(15))\n",
    "d = g/m\n",
    "plt.imshow(d,cmap=plt.cm.gray)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import rank as skr\n",
    "\n",
    "m = skr.median(g,disk(12))\n",
    "p = g-.9*m\n",
    "\n",
    "plt.imshow(p)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_hist(data.coins())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = data.coins()\n",
    "t = (g>120).astype(np.uint8)\n",
    "plt.imshow(t,interpolation='nearest')\n",
    "plt.colorbar()\n",
    "print(t.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m= skr.median(t,disk(5))\n",
    "plt.imshow(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = data.coins()\n",
    "t = (g>90).astype(np.uint8)\n",
    "m = skr.median(t,disk(5))\n",
    "plt.imshow(t,cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_hist(data.camera())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = data.camera()\n",
    "t1 = (g>150).astype(int)\n",
    "t2 = (g>200).astype(int)\n",
    "t3 = t1+t2\n",
    "t = g<100\n",
    "plt.imshow(t)\n",
    "t3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_hist(data.hubble_deep_field()[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_hist(data.moon())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_hist(data.coffee())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## percentile threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ima = data.hubble_deep_field()[:,:,0]\n",
    "display_hist(ima)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know a priori the surface of the object of interest, here the galaxies, one can set the threshold to the corresponding percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = .95 #galaxies are the 5% brighter pixels in the image\n",
    "\n",
    "h,bins = np.histogram(ima[:],range(256))\n",
    "\n",
    "c = 1.*np.cumsum(h)/np.sum(h)\n",
    "plt.plot(c)\n",
    "\n",
    "plt.gca().hlines(perc,0,plt.gca().get_xlim()[1]);\n",
    "\n",
    "th_perc = np.where(c>=perc)[0][0]\n",
    "\n",
    "plt.gca().vlines(th_perc,0,plt.gca().get_ylim()[1]);\n",
    "plt.figure()\n",
    "plt.imshow(ima>=th_perc);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimal threshold\n",
    "algorithm:\n",
    "\n",
    "1. set an initial threshold to $T$\n",
    "2. cut distribution into:\n",
    "$$G1 = \\{p(x,y)>T\\}$$\n",
    "$$G2 = \\{p(x,y)<=T\\}$$\n",
    "3. compute distribution centroid for each part $m1$ and $m2$\n",
    "4. the new threshold is given by:\n",
    "$$Tâ€™=(m1+m2)/2$$\n",
    "5. iterate (2) until convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question:\n",
    "* write a function that finds the optimal threshold for the cameraman\n",
    "* what clustering method (machine mearning) is equivallent to that algorithm ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otsu's threshold\n",
    "\n",
    "One define two classes (e.g. foreground/background) based on pixel intensity, classes are separated by a threshold value $k$:\n",
    "\n",
    "the class probabilities are defined such as:\n",
    "\n",
    "$$\n",
    "\\begin{align*} \n",
    "\\omega_0 &=& Pr(C_0) = \\sum_{i=0}^k p_i  = \\omega (k)\\\\\n",
    "\\omega_1 &=& Pr(C_1) = \\sum_{i=k+1}^L p_i  = 1-\\omega (k)\\\\\n",
    "\\end{align*} \n",
    "$$\n",
    "\n",
    "the class means are defined by:\n",
    "\n",
    "$$\n",
    "\\begin{align*} \n",
    "\\mu_0 &=& \\sum_{i=0}^k i\\:Pr(i|C_0) = \\sum_{i=0}^k i\\:p_i/\\omega_0 = \\mu(k)/\\omega(k) \\\\\n",
    "\\mu_1 &=& \\sum_{i=k+1}^L i\\:Pr(i|C_1) = \\sum_{i=k+1}^L i\\:p_i/\\omega_1 = \\frac{\\mu_T - \\mu(k)}{1-\\omega(k)} \\\\\n",
    "\\end{align*} \n",
    "$$\n",
    "\n",
    "with \n",
    "\n",
    "$$\n",
    "\\begin{align*} \n",
    "\\mu(k) &=& \\sum_{i=0}^k i\\: p_i\\\\\n",
    "\\end{align*} \n",
    "$$\n",
    "\n",
    "for the total image one have:\n",
    "\n",
    "$$\n",
    "\\begin{align*} \n",
    "\\mu_T &=& \\mu(L) = \\sum_{i=0}^L i\\: p_i  \n",
    "\\end{align*} \n",
    "$$\n",
    "\n",
    "total image values and class values are linked with:\n",
    "\n",
    "$$\n",
    "\\begin{align*} \n",
    "\\omega_0 \\mu_0 + \\omega_1  \\mu_1 &=& \\mu_T\\\\\n",
    "\\omega_0 + \\omega_1 &=& 1\n",
    "\\end{align*} \n",
    "$$\n",
    "\n",
    "class variances are defined by:\n",
    "\n",
    "$$\n",
    "\\begin{align*} \n",
    "\\sigma_0^2 &=& \\sum_{i=0}^k (i-\\mu_0)^2\\:Pr(i|C_0) =\\sum_{i=0}^k (i-\\mu_0)^2 p_i/\\omega_0\\\\\n",
    "\\sigma_1^2 &=& \\sum_{i=k+1}^L (i-\\mu_1)^2\\:Pr(i|C_1) =\\sum_{i=k+1}^L (i-\\mu_1)^2 p_i/\\omega_1\\\\\n",
    "\\end{align*} \n",
    "$$\n",
    "\n",
    "variance intra-classe (within):\n",
    "\n",
    "$$\\sigma_W^2 = \\omega_0 \\sigma_0^2 + \\omega_1 \\sigma_1^2$$\n",
    "\n",
    "variance inter-classe (between):\n",
    "$$\n",
    "\\begin{align*} \n",
    "\\sigma_B^2 &=& \\omega _0 (\\mu_0 - \\mu_T)^2 + \\omega_1(\\mu_1-\\mu_T)^2\\\\\n",
    "&=& \\omega_0 \\omega_1(\\mu_1-\\mu_0)^2\n",
    "\\end{align*} \n",
    "$$\n",
    "\n",
    "total variance:\n",
    "$$\\sigma_T^2 = \\sum_{i=0}^L (i-\\mu_T)^2 p_i$$\n",
    "\n",
    "separability:\n",
    "$$\\lambda = \\sigma_B^2/\\sigma_W^2 \\:,\\: \\kappa = \\sigma_T^2/\\sigma_W^2 \\:,\\: \\eta = \\sigma_B^2/\\sigma_T^2 $$\n",
    "\n",
    "Otsu's threshold is $k$ such that separability is maximal (e.g.):\n",
    "\n",
    "$$\\eta = \\sigma_B^2(k)/\\sigma_T^2(k)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "ima = 255*(1-data.camera())\n",
    "th = threshold_otsu(ima)\n",
    "display_hist(ima)\n",
    "plt.gca().vlines(th,0,plt.gca().get_ylim()[1]);\n",
    "plt.title(\"Otsu's thresold = %d\"%th );\n",
    "plt.imshow(ima>th,interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">see also:\n",
    "* Otsu's method [Otsu79](../00-Preface/06-References.ipynb#[Otsu79]) p432"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## entropy threshold\n",
    "\n",
    "The threshold is the value maximizing total entropy, which is the sum of the two subspaces entropies below and above the threshold.\n",
    "\n",
    "$$ e = - \\sum p \\, log_2 (p) $$\n",
    "\n",
    "where $p$ is the probability of occurence for one gray level in one specific subspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ima = data.astronaut()[:,:,0]\n",
    "\n",
    "h,_ = np.histogram(ima[:],range(256))\n",
    "h = h/h.sum() # normalized histogram\n",
    "\n",
    "def entropy(symb,freq):\n",
    "    idx = np.asarray(freq) != 0\n",
    "    s = np.sum(freq)\n",
    "    p = 1. * freq/s\n",
    "    e = - np.sum(p[idx] * np.log2(p[idx]))\n",
    "    return e\n",
    "\n",
    "e0 = []\n",
    "e1 = []\n",
    "\n",
    "for g in range(1,255):\n",
    "    e0.append(entropy(range(0,g),h[:g]))\n",
    "    e1.append(entropy(range(g,255),h[g:255]))\n",
    "\n",
    "e0 = np.asarray(e0)\n",
    "e1 = np.asarray(e1)\n",
    "\n",
    "e_max = np.argmax(e0+e1)\n",
    "plt.plot(e0)\n",
    "plt.plot(e1)\n",
    "plt.plot(e0+e1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(h)\n",
    "plt.gca().vlines(e_max,0,plt.gca().get_ylim()[1]);\n",
    "plt.figure()\n",
    "plt.imshow(ima>e_max,cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_hist(ima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multi-spectral theshold\n",
    "\n",
    "For multi-spectral images (e.g. rgb, hsv, etc) one can consider each spectral plane independently and group the obtained segmentations.\n",
    "\n",
    "The following example apply an Otsu's threshold on each color plane and make a combine the segmented results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu\n",
    "from skimage.color import rgb2hsv\n",
    "\n",
    "rgb = data.immunohistochemistry()\n",
    "\n",
    "r = rgb[:,:,0]\n",
    "g = rgb[:,:,1]\n",
    "b = rgb[:,:,2]\n",
    "\n",
    "th_r = threshold_otsu(r)\n",
    "th_g = threshold_otsu(g)\n",
    "th_b = threshold_otsu(b)\n",
    "\n",
    "mix = (r>th_r).astype(np.uint8) + 2 * (g>th_g).astype(np.uint8) + 4 * (b>th_b).astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.imshow(rgb)\n",
    "\n",
    "plt.figure(figsize=[8,4])\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(r>th_r)\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(g>th_g)\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(b>th_b)\n",
    "\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.imshow(mix)\n",
    "plt.colorbar();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "* what appens in an other color space ?\n",
    "* can we use this approach for images that are not multi-spectral ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding spectral dimensions\n",
    "\n",
    "Sometime the gray level information is not enough to segment the image, the folowing image presents clearly 3 regions of different average gray level.\n",
    "\n",
    "Howerver, we also distinguish a variable texture in the central part of the image, the texture is more coarse than on the lateral borders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.filters.rank as skr\n",
    "from skimage.morphology import disk\n",
    "\n",
    "ima = (128*np.ones((255,255))).astype(np.uint8)\n",
    "ima[50:100,50:150] = 150\n",
    "ima[130:200,130:200] = 100\n",
    "\n",
    "ima = skr.mean(ima,disk(10))\n",
    "\n",
    "mask = 10.*np.ones_like(ima)\n",
    "mask[:,100:180] = 15\n",
    "# add variable noise\n",
    "\n",
    "n = np.random.random(ima.shape)-.5\n",
    "ima = (ima + mask*n).astype(np.uint8)\n",
    "\n",
    "\n",
    "entropy = 255.*skr.entropy(ima,disk(4))/8\n",
    "\n",
    "plt.figure(figsize=[8,8])\n",
    "plt.imshow(ima,cmap=plt.cm.gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the gray level histogram exhibits three peaks corresponding to the three gray levels present in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_hist(ima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to detect the variation of noise inside the central part, one can use a local entropy measurement, we now observe a clear contrast between the central band and the image left and right borders. Entropy is also sensitive to sharp gray level variation, so the box borders are also emphasized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_hist(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.zeros_like(ima)\n",
    "r[ima>110] = 1\n",
    "r[ima>140] = r[ima>140]+1\n",
    "\n",
    "plt.imshow(r)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.zeros_like(entropy)\n",
    "s[entropy>110] = 1\n",
    "s[entropy>140] = 0\n",
    "plt.imshow(s)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(s+2*r)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
